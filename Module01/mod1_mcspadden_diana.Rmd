---
title: "mod1_mcspadden-diana"
author: "Diana McSpadden (hdm5s)"
date: "2/2/2021"
output: html_document
---

# Module 1 Homework
## H. Diana McSpadden (hdm5s)

Complete exercises 1, 2, 6, 8, and 10 at the end of Chapter 2 of your textbook. Attempt each of these exercises prior to the live session since they will likely serve as material for discussion and interaction. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=10, fig.height=8)
```


```{r}
library(tidyverse)
library(scales)
library(ggplot2)
```

## Exercise 1
For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be
better or worse than an inflexible method. Justify your answer.

#### (a) The sample size n is extremely large, and the number of predictors p is small.

ANSWER: **Inflexible**, this is an ideal regression data set. We can possibly create an accurate model that is also interpretable.

#### (b) The number of predictors p is extremely large, and the number of observations n is small.

ANSWER: **Inflexible** or **Flexible**, I could recommend two different approached: lasso method if the n is large enough and we want to select which of the parameters are most useful. Lasso will help with feature selection. However, if n is really small, a flexible method such a a support vector machine 

#### (c) The relationship between the predictors and response is highly non-linear.

ANSWER: **Flexible** because highly non-linear function decision boundaries require flexible approaches.

#### (d) The variance of the error terms, i.e. Ïƒ2 = Var(E), is extremely high.

ANSWER: This scenario requires a **flexible** method. Standard variance is an assumption for lasso, or regression methods and with a highly variable standard deviation

## Exercise 2
Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction.
Finally, provide n and p.

#### (a) We collect a set of data on the top 500 firms in the US...
For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.


ANSWER: This scenario is a **regression** problem specifically interested in determining **inference**, so an interpretable model is important. A regression solution will provide the coefficients for each parameter which allow comparison of parameter influence on CEO salary. n = 500, p = 3. 

#### (b) We are considering launching a new product and wish to know whether it will be a success or a failure...
We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.


ANSWER: This is a **categorization** problem with "success" or "failure" categories. In this scenario we are interested in **predicting** whether our new product will succeed or fail. n = 20, p = 13.

#### (c) We are interest in predicting the % change in the USD/Euro

ANSWER: **Regression**, we are trying to **predict** a continuous value, not a condition. n = number of changes in USD/Euro in our data set. p = parameters in our data that we believe predict USD/Euro currency rate change.

## Exercise 6: 
Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?


**ANSWER: **

Parametric approaches assume the shape of the function will be a specific linear shape. The advantage of a parametric approach is that it simplifies the fitting problem to estimating coefficients in the function, typically by reducing squared error from the mean, while keeping a linear function for the range. THe downside to assuming the form of the function is that the estimated function could be far from the true form. However, parametric approaches are 

Non-parametric approaches assume no such restrictions on the model's form, and thus try to map to the data points as closely as possible while minimizing variance (as configured). Non-parametric approaches require a large number of observations in order to limit over-fitting. Non-parametric approaches can also introduce excess bias, but if bias and over-fitting are controlled they may provide a better estimation of the funciton.


## Execise 8
This exercise relates to the College data set, which can be found in the file College.csv.

...

### (a) Use the read.csv() function to read the data into R. 
Call the loaded data college. Make sure that you have the directory set to the correct location for the data.


```{r q8a1}
college <- read.csv("College.csv")
head(college)
```

### (b) fix() ...
```{r q8b-1}
rownames(college) = college[,1] # first column is the name of the university
fix (college) #fix pops up a "fix" form to edit the data
```


```{r q8b-2}
college =college [,-1] #remove the first column
fix (college )
```

### (c) summary() and plotting

#### i: Use the summary() function
```{r q8ci-1}
summary(college) # display summary statistics and data information
```

#### ii. Use the pairs() function 
```{r q8cii-1, out.width = '80%'}
#?pairs
pairs(college[,2:11])
```

#### iii. plot() function
```{r q8ciii-1}
# plot side by side boxplots of Outstate versus Private (Private universities have more out of state students):
boxplot(college$Outstate~college$Private)
```

#### iv. Create a new qualitative variable, called Elite, ...
by binning the Top10perc variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50%.

```{r q8civ-1}
#?rep
Elite = rep("No",nrow(college )) # replicates the values in x.

Elite[college$Top10perc > 50]=" Yes" #for indexes where top 10% is above 50%, set Elite to "Yes"

Elite = as.factor (Elite) # set Elite as a factor Yes/No

college = data.frame(college ,Elite) # append the new Elite column to the college dataframe

```

```{r q8civ-2}
head(college) # show with new Elite column
```


```{r q8civ-3}
summary(college)
```

```{r q8civ-4}

boxplot(college$Outstate~college$Elite)
```

#### v. Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative variables.

```{r q8cv-1}

par(mfrow=c(5,2))

hist(college$PhD, breaks=10, main="Perc Faculty with PhD - 10 bins")

hist(college$PhD, breaks=20, main="Perc Faculty with PhD - 20 bins")

hist(college$S.F.Ratio, breaks=10, main="Student Faculty Ratio - 10 bins")

hist(college$Expend, breaks=5, main="Instructional Expend/Student - 10 bins")

hist(college$Top10perc, breaks=10, main="Perc Students From Top 10% - 10 bins")

hist(college$Top25perc, breaks=10, main="Perc Students From Top 25% - 10 bins")

hist(college$Grad.Rate, breaks=10, main="Graduation Rate - 10 bins")

hist(college$Grad.Rate, breaks=4, main="Graduation Rate - 4 bins")

hist(college$Accept, breaks=10, main="Number Apps Accepted - 10 bins")

hist(college$Accept, breaks=16, main="Number Apps Accepted - 16 bins")
```

#### v. Continue exploring the data, and provide a brief summary of what you discover.

```{r q8cv-2}
# scale/normalize the data
college_standardized <- as.data.frame(scale(select(college, -c(Private,Elite))))
head(college_standardized)

```



**Visualize the scaled data for a few fields
```{r}


par(mfrow=c(4,2))

hist(college_standardized$PhD, breaks=10, main="Scaled Perc Faculty with PhD - 10 bins")

hist(college_standardized$S.F.Ratio, breaks=10, main="Scaled Student Faculty Ratio - 10 bins")

hist(college_standardized$Expend, breaks=5, main="Scaled Instructional Expend/Student - 10 bins")

hist(college_standardized$Top10perc, breaks=10, main="Scaled Perc Students From Top 10% - 10 bins")

hist(college_standardized$Top25perc, breaks=10, main="Scaled Perc Students From Top 25% - 10 bins")

hist(college_standardized$Grad.Rate, breaks=10, main="Scaled Graduation Rate - 10 bins")

hist(college_standardized$Accept, breaks=10, main="Scaled Number Apps Accepted - 10 bins")
```

```{r fig.height=15}
par(mfrow=c(4,2))

boxplot(college$P.Undergrad~college$Elite, main='Num Partime Undergrads by Elite Status')

boxplot(college$Outstate~college$Elite, main='Out-of-state Tuition by Elite Status')

boxplot(college$Room.Board~college$Elite, main='Room and Board Costs by Elite Status')

boxplot(college$Books~college$Elite, main='Book Costs by Elite Status')

boxplot(college$Personal~college$Elite, main='Personal Costs by Elite Status')

boxplot(college$PhD~college$Elite, main='Perc Faculty with PhD by Elite Status')

boxplot(college$Grad.Rate~college$Elite, main='Grad Rate by Elite Status')

boxplot(college$perc.alumni~college$Elite, main='Perc Alumni Who Donate by Elite Status')
```


**Interesting Findings**

1. Graduation Rate and Top25 Perc, have normal distributions across the colleges in the sample
2. Across our sample, "Elite Colleges", defined by high school grads in top 10% of class make up 50% of admissions, have:
  * higher graduation rates
  * greater perc of alumni who donate
  * higher perc of faculty with PhD's
  * higher room and board costs
  * and higher out-of-state tuition
3. However, Elite Colleges have similar:
  * book costs
  * estimated personal spending
  * and perc of part-time undergradutes


## Exercise 10
This exercise involves the Boston housing data set.

### (a) load in the Boston data set. 

```{r q10a-1}
library(MASS)
?Boston
dim(Boston)
```

The Boston data frame has 506 rows and 14 columns.

* crim: per capita crime rate by town.
* zn: proportion of residential land zoned for lots over 25,000 sq.ft.
* indus: proportion of non-retail business acres per town.
* chas: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
* nox: nitrogen oxides concentration (parts per 10 million).
* rm: average number of rooms per dwelling.
* age: proportion of owner-occupied units built prior to 1940.
* dis: weighted mean of distances to five Boston employment centres.
* rad: index of accessibility to radial highways.
* tax: full-value property-tax rate per \$10,000.
* ptratio: pupil-teacher ratio by town.
* black: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.
* lstat: lower status of the population (percent).
* medv: median value of owner-occupied homes in \$1000s.


**ANSWER: ** There are 506 rows and 14 columns in the Boston dataframe.

```{r q10a-1}
head(Boston)
```


### (b) Make some pairwise scatterplots ...
of the predictors (columns) inthis data set. Describe your findings.



### (c) Are any of the predictors associated with per capita crime rate?
If so, explain the relationship.



### (d) Do any of the suburbs of Boston appear to have ...
* articularly high crime rates? 
* Tax rates? 
* Pupil-teacher ratios? 

Comment on the range of each predictor.


### (e) How many of the suburbs in this data set bound the Charles river?


### (f) What is the median pupil-teacher ratio among the towns in this data set?



### (g) Which suburb of Boston has lowest median value of owneroccupied homes? 
What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.


### (h) In this data set, how many of the suburbs:

* average more than seven rooms per dwelling? 
* More than eight rooms per dwelling?

Comment on the suburbs that average more than eight rooms per dwelling.









