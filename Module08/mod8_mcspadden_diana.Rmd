---
title: "Module 8 HW McSpadden_Diana"
author: "Diana McSpadden"
date: "4/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Q7
In the lab, we applied random forests to the Boston data using mtry=6 and using ntree=25 and ntree=500. Create a plot displaying the test error resulting from random forests on this data set for a more comprehensive range of values for mtry and ntree. You can model your plot after Figure 8.10. Describe the results obtained.

```{r q7-setup, warning=FALSE}
library(MASS)
library(tree)
library(tidyverse)
library(partykit)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
```

Setup train and test observations
```{r q7-1}

boston <- MASS::Boston
set.seed(1976)

n = nrow(boston)


train = sample(1: nrow(boston ), 406, replace = FALSE) # 406 training observations
```

The argument **mtry=13** indicates that all 13 predictors should be considered for each split of the tree. 

I want to run for m = range(1:13).

We change the number of trees grown by randomForest() using the **ntree** argument.

I want to run with ntree in seq(from = 25, to = 500, by = 25)
```{r q7-2, cache=TRUE}

out_trees = tibble()

for (m in c(1,4,7,10,13))
{
  for (nt in seq(from = 1, to = 1000, by = 25))
  {
    set.seed(200)
    tree_model = randomForest(medvâˆ¼., data = boston, subset=train, mtry = m, ntree = nt)
    preds = predict(tree_model, newdata = boston[-train,])
    preds_err = mean((preds - boston[-train, ]$medv)^2)
    
    # save the tuning and errors
    out_trees = bind_rows(out_trees, tibble(mtry = m, ntree = nt, err = preds_err))
  }
}
```

``` {r q7-3}
# can save mtry as a factor and then the plot will color correctly
out_trees %>% mutate(mtry = factor(mtry)) %>% filter(err == min(err))

```

**My minimum error randomForrest used mtry = 10 and ntree = 26.**


Now I will create a plot:
```{r q7-4}

out_trees %>% ggplot(aes(x = ntree, y = err, color=factor(mtry))) + geom_line() #+ geom_point(aes(colour = factor(mtry))) #


```
**Answer Q7:** One can see that the mtry = 1 performed poorly no matter the number of trees; it is expected that using/comparing single predictor at each split would not perform well. One can see that 10 predictors was the best balance of bias and variance when using random forests, and that 26 trees was adequate to produce the lowest error rate.

# Question 8
In the lab, a classification tree was applied to the Carseats data set after converting Sales into a qualitative response variable. Now we will seek to predict Sales using regression trees and related approaches, treating the response as a quantitative variable.

## (a) Split the data set into a training set and a test set.

## (b) Fit a regression tree to the training set. 
Plot the tree, and interpret the results. What test MSE do you obtain?

## (c) Use cross-validation ...
in order to determine the optimal level of tree complexity. Does pruning the tree improve the test MSE?

## (d) Use the bagging approach ...
in order to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important.

## (e) Use random forests to analyze this data. 
What test MSE do you obtain? Use the importance() function to determine which variables aremost important. Describe the effect of m, the number of variables considered at each split, on the error rate obtained.

# Question 11
This question uses the Caravan data set.

## (a) Create a training set consisting of the first 1,000 observations,
and a test set consisting of the remaining observations.

## (b) Fit a boosting model to the training set...
with Purchase as the response and the other variables as predictors. Use 1,000 trees, and a shrinkage value of 0.01. Which predictors appear to be the most important?

## (c) Use the boosting model to predict the response on the test data.
Predict that a person will make a purchase if the estimated probability of purchase is greater than 20 %. Form a confusion matrix. What fraction of the people predicted to make a purchase do in fact make one? How does this compare with the results
obtained from applying KNN or logistic regression to this data set?

